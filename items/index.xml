<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Items on yusuf</title>
    <link>https://wandayusufalvian.github.io/items/</link>
    <description>Recent content in Items on yusuf</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Jun 2021 13:39:51 +0700</lastBuildDate><atom:link href="https://wandayusufalvian.github.io/items/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Surpass Lightgbm Warning</title>
      <link>https://wandayusufalvian.github.io/items/surpass-lightgbm-warning/</link>
      <pubDate>Sun, 27 Jun 2021 13:39:51 +0700</pubDate>
      
      <guid>https://wandayusufalvian.github.io/items/surpass-lightgbm-warning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compare train_test_split and StratifiedShuffleSplit in Scikit-learn</title>
      <link>https://wandayusufalvian.github.io/items/benchmark-1/</link>
      <pubDate>Fri, 25 Jun 2021 11:11:33 +0700</pubDate>
      
      <guid>https://wandayusufalvian.github.io/items/benchmark-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Grokking Algorithms</title>
      <link>https://wandayusufalvian.github.io/items/grokking-algorithms/</link>
      <pubDate>Tue, 08 Jun 2021 14:15:26 +0700</pubDate>
      
      <guid>https://wandayusufalvian.github.io/items/grokking-algorithms/</guid>
      <description> summary of &amp;ldquo;Grokking Algorithms&amp;rdquo; Book i think this is the best &amp;ldquo;short&amp;rdquo; book to review Algorithm lecture that taught in College if you want to review Algorithm lecture, i recommend this book  </description>
    </item>
    
    <item>
      <title>GBDT Hyperparameter Tuning Benchmark</title>
      <link>https://wandayusufalvian.github.io/items/hyperparameter-tuning/</link>
      <pubDate>Tue, 08 Jun 2021 08:34:38 +0700</pubDate>
      
      <guid>https://wandayusufalvian.github.io/items/hyperparameter-tuning/</guid>
      <description> implement BOHB, state of the art method for Hyperparameter Optimization (HPO) Method Compare to 3 other HPO method : random search, grid search, and bayes search  </description>
    </item>
    
    <item>
      <title>The 10x Rules</title>
      <link>https://wandayusufalvian.github.io/items/the-10x-rules/</link>
      <pubDate>Tue, 08 Jun 2021 08:34:38 +0700</pubDate>
      
      <guid>https://wandayusufalvian.github.io/items/the-10x-rules/</guid>
      <description> summary of The 10X Rules Book in nutshell : &amp;ldquo;Success is your duty and you have to work beyond average (10x) to be successful&amp;rdquo;  </description>
    </item>
    
  </channel>
</rss>
